# scripts/rag_api.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_ollama import OllamaLLM, OllamaEmbeddings
from langchain_community.vectorstores import Qdrant
from qdrant_client import QdrantClient
import uvicorn
import logging
from typing import List, Optional
import os
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="RAG API –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ",
    description="API –¥–ª—è –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ",
    version="1.0.0"
)

# –ú–æ–¥–µ–ª–∏ –∑–∞–ø—Ä–æ—Å–æ–≤/–æ—Ç–≤–µ—Ç–æ–≤
class QuestionRequest(BaseModel):
    question: str
    top_k: Optional[int] = 5

class DocumentResponse(BaseModel):
    content: str
    source: str
    score: float

class AnswerResponse(BaseModel):
    question: str
    answer: str
    sources: List[DocumentResponse]
    processing_time: float

class HealthResponse(BaseModel):
    status: str
    ollama_available: bool
    qdrant_available: bool
    models_loaded: bool

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
try:
    OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://host.docker.internal:11434")
    
    llm = OllamaLLM(
        model="deepseek-r1:8b",
        base_url=OLLAMA_HOST,
        temperature=0.1,
        num_ctx=8192
    )
    
    embeddings = OllamaEmbeddings(
        model="nomic-embed-text:latest",
        base_url=OLLAMA_HOST
    )
    
    qdrant_client = QdrantClient(host="localhost", port=6333)
    vector_store = Qdrant(
        client=qdrant_client,
        collection_name="bashkir_energo_docs_nomic",
        embeddings=embeddings
    )
    
    logger.info("‚úÖ –ú–æ–¥–µ–ª–∏ –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
    MODELS_LOADED = True
except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
    MODELS_LOADED = False

@app.get("/", summary="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ API")
async def root():
    return {
        "message": "RAG API –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ",
        "version": "1.0.0",
        "endpoints": {
            "health": "/health - —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–∞",
            "ask": "/ask - –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å",
            "search": "/search - –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
        }
    }

@app.get("/health", response_model=HealthResponse, summary="–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Ollama
        ollama_available = False
        try:
            # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –∫ Ollama
            test_response = llm.invoke("test")
            ollama_available = bool(test_response)
        except:
            ollama_available = False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Qdrant
        qdrant_available = False
        try:
            collections = qdrant_client.get_collections()
            qdrant_available = True
        except:
            qdrant_available = False
        
        return HealthResponse(
            status="healthy" if (MODELS_LOADED and ollama_available and qdrant_available) else "degraded",
            ollama_available=ollama_available,
            qdrant_available=qdrant_available,
            models_loaded=MODELS_LOADED
        )
    except Exception as e:
        logger.error(f"Health check error: {e}")
        return HealthResponse(
            status="unhealthy",
            ollama_available=False,
            qdrant_available=False,
            models_loaded=False
        )

@app.post("/ask", response_model=AnswerResponse, summary="–ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å —Å–∏—Å—Ç–µ–º–µ")
async def ask_question(request: QuestionRequest):
    """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ"""
    if not MODELS_LOADED:
        raise HTTPException(status_code=503, detail="–°–µ—Ä–≤–∏—Å –Ω–µ –≥–æ—Ç–æ–≤")
    
    start_time = datetime.now()
    
    try:
        logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å: {request.question}")
        
        # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        retriever = vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": request.top_k}
        )
        
        docs = retriever.invoke(request.question)
        
        if not docs:
            return AnswerResponse(
                question=request.question,
                answer="–í –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É",
                sources=[],
                processing_time=(datetime.now() - start_time).total_seconds()
            )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "\n\n".join([
            f"[–î–æ–∫—É–º–µ–Ω—Ç: {doc.metadata.get('source', 'Unknown')}]\n{doc.page_content}"
            for doc in docs
        ])
        
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è DeepSeek
        prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ. –û—Ç–≤–µ—Ç—å —Ç–æ—á–Ω–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.

–ö–û–ù–¢–ï–ö–°–¢ (–¥–æ–∫—É–º–µ–Ω—Ç—ã –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ):
{context}

–í–û–ü–†–û–°:
{request.question}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, —Å–∫–∞–∂–∏ "–í –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É"
3. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω—ã–º –≤ —Ü–∏—Ñ—Ä–∞—Ö, –¥–∞—Ç–∞—Ö –∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞—Ö
4. –î–ª—è —Ç–∞—Ä–∏—Ñ–æ–≤ –∏ –Ω–æ—Ä–º–∞—Ç–∏–≤–æ–≤ —É–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
5. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç, –µ—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–±—ä–µ–º–Ω–∞—è

–û–¢–í–ï–¢:"""
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        answer = llm.invoke(prompt)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
        sources = []
        for doc in docs:
            sources.append(DocumentResponse(
                content=doc.page_content[:500] + "..." if len(doc.page_content) > 500 else doc.page_content,
                source=doc.metadata.get('source', 'Unknown'),
                score=doc.metadata.get('score', 0.0)
            ))
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"‚úÖ –í–æ–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {processing_time:.2f} —Å–µ–∫")
        
        return AnswerResponse(
            question=request.question,
            answer=answer.strip(),
            sources=sources,
            processing_time=processing_time
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}")

@app.post("/search", summary="–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –±–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞")
async def search_documents(request: QuestionRequest):
    """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –±–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"""
    if not MODELS_LOADED:
        raise HTTPException(status_code=503, detail="–°–µ—Ä–≤–∏—Å –Ω–µ –≥–æ—Ç–æ–≤")
    
    try:
        retriever = vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": request.top_k}
        )
        
        docs = retriever.invoke(request.question)
        
        results = []
        for doc in docs:
            results.append(DocumentResponse(
                content=doc.page_content,
                source=doc.metadata.get('source', 'Unknown'),
                score=doc.metadata.get('score', 0.0)
            ))
        
        return {
            "question": request.question,
            "documents_found": len(results),
            "documents": results
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}")

@app.get("/collections", summary="–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–ª–ª–µ–∫—Ü–∏–π")
async def get_collections():
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–æ–ª–ª–µ–∫—Ü–∏—è—Ö –≤ Qdrant"""
    try:
        collections = qdrant_client.get_collections()
        return {
            "collections": collections.collections,
            "total": len(collections.collections)
        }
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–π: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–π: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(
        "rag_api:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )