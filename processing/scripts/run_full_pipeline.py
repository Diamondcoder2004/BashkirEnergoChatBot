#!/usr/bin/env python3
"""
–ö–æ–Ω—Å–æ–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è RAG-–∫–æ–Ω–≤–µ–π–µ—Ä–æ–º
"""
import subprocess
import sys
import os
from pathlib import Path
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
load_dotenv('/app/.env')

EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL', 'sentence-transformers/all-MiniLM-L6-v2')
COLLECTION_NAME = os.getenv('COLLECTION_NAME', 'bashkir_energo_docs')

def run_command(cmd, description):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–∞–Ω–¥—É –∏ –≤—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
    print(f"\nüöÄ {description}")
    print(f"–ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd) if isinstance(cmd, list) else cmd}")
    
    try:
        result = subprocess.run(cmd, shell=isinstance(cmd, str), 
                              check=True, capture_output=True, text=True)
        print("‚úÖ –£—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
        if result.stdout:
            print(f"–í—ã–≤–æ–¥: {result.stdout}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        if e.stderr:
            print(f"–í—ã–≤–æ–¥ –æ—à–∏–±–∫–∏: {e.stderr}")
        return False

def parse_pdf_to_md():
    """1. –ü–∞—Ä—Å–∏–Ω–≥ PDF –≤ Markdown"""
    print("\n" + "="*60)
    print("üìÑ –ü–∞—Ä—Å–∏–Ω–≥ PDF –≤ Markdown —Å OCR")
    return run_command(["python", "scripts/parse_docs_ocr.py"], "–ü–∞—Ä—Å–∏–Ω–≥ PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

def semantic_chunking():
    """2. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —á–∞–Ω–∫–∏–Ω–≥"""
    print("\n" + "="*60)
    print("üî™ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —á–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    return run_command(["python", "scripts/semantic_chunking.py"], "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —á–∞–Ω–∫–∏–Ω–≥")

def chunk_encoding():
    """3. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î"""
    print("\n" + "="*60)
    print("üóÑÔ∏è –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î")
    return run_command(["python", "scripts/chunk_embedding_qdrant.py"], "–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã")

def change_encoder_qdrant():
    """4. –°–º–µ–Ω–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞ –≤ Qdrant"""
    print("\n" + "="*60)
    print("üîÑ –°–º–µ–Ω–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞ –≤ Qdrant")
    return run_command(["python", "scripts/change_embedder_qdrant.py"], "–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å rubert –º–æ–¥–µ–ª—å—é")

def check_dependencies():
    """5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    print("\n" + "="*60)
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π")
    
    try:
        import requests
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Qdrant
        try:
            response = requests.get(f"http://{os.getenv('QDRANT_HOST', 'localhost')}:6333", timeout=5)
            print("‚úÖ Qdrant: –¥–æ—Å—Ç—É–ø–µ–Ω")
        except:
            print("‚ùå Qdrant: –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Ollama
        try:
            response = requests.get(f"{os.getenv('OLLAMA_HOST', 'http://localhost:11434')}/api/tags", timeout=5)
            print("‚úÖ Ollama: –¥–æ—Å—Ç—É–ø–µ–Ω")
        except:
            print("‚ö†Ô∏è  Ollama: –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        dirs_to_check = [
            ("üìÅ –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã", Path("/app/data/documents")),
            ("üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ MD", Path("/app/data/output")),
            ("üìÅ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —á–∞–Ω–∫–∏", Path("/app/data/semantic_chunks"))
        ]
        
        for name, path in dirs_to_check:
            if path.exists():
                files = list(path.glob("*"))
                print(f"{name}: {len(files)} —Ñ–∞–π–ª–æ–≤")
            else:
                print(f"{name}: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                
        print(f"\nüîß –¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
        print(f"   –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {EMBEDDING_MODEL}")
        print(f"   –ö–æ–ª–ª–µ–∫—Ü–∏—è: {COLLECTION_NAME}")
        
    except ImportError:
        print("‚ùå requests –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

def main():
    """–û—Å–Ω–æ–≤–Ω–æ–µ –º–µ–Ω—é"""
    print("ü§ñ RAG Pipeline Manager")
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    Path("/app/data/documents").mkdir(parents=True, exist_ok=True)
    Path("/app/data/output").mkdir(parents=True, exist_ok=True)
    Path("/app/data/semantic_chunks").mkdir(parents=True, exist_ok=True)
    
    while True:
        print("\n" + "="*40)
        print("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É:")
        print("1. parse_pdf_to_md")
        print("2. semantic_chunking") 
        print("3. chunk_encoding")
        print("4. change_encoder_qdrant")
        print("5. check_dependencies")
        print("6. exit")
        print("-"*40)
        
        choice = input("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã (1-6): ").strip()
        
        if choice == '1':
            parse_pdf_to_md()
        elif choice == '2':
            semantic_chunking()
        elif choice == '3':
            chunk_encoding()
        elif choice == '4':
            change_encoder_qdrant()
        elif choice == '5':
            check_dependencies()
        elif choice == '6':
            print("üëã –í—ã—Ö–æ–¥...")
            break
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")

if __name__ == "__main__":
    main()