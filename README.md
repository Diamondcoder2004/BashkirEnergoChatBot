# RAG-система для Башкирэнерго

## Описание проекта

Данный проект представляет собой Retrieval-Augmented Generation (RAG) систему, разработанную для обработки и анализа документов компании Башкирэнерго. Система позволяет эффективно извлекать информацию из больших объемов документации и отвечать на вопросы на основе содержимого этих документов.

Основные компоненты системы:
- Языковая модель Saiga-llama3 для генерации ответов
- Модель MiniLM-L12-v2 для создания векторных эмбеддингов
- Ранжирующая модель Qwen3-Reranker-0.6B для улучшения релевантности результатов
- Векторная база данных Qdrant для хранения и поиска
- Механизмы семантического разбиения и контекстного сжатия

## Архитектура системы

Система состоит из следующих основных компонентов:

- **Языковая модель Saiga-llama3**: используется для генерации ответов на вопросы и контекстного сжатия
- **Модель MiniLM-L12-v2**: обеспечивает создание векторных эмбеддингов для документов
- **Ранжирующая модель Qwen3-Reranker-0.6B**: улучшает релевантность результатов поиска путем переупорядочивания документов
- **Векторная база данных Qdrant**: используется для хранения и поиска векторных представлений документов
- **Langchain**: фреймворк для построения RAG-конвейера и оркестрации компонентов
- **OCR-модуль**: обеспечивает обработку сканированных документов и изображений

## Установка и запуск

### Предварительные требования

Для работы системы необходимо установить следующие компоненты:

1. Docker и Docker Compose
2. NVIDIA Docker runtime (для GPU-ускорения, опционально)
3. Ollama с необходимыми моделями

### Установка моделей

Установите требуемые модели с помощью Ollama:

```bash
ollama pull bambucha/saiga-llama3
ollama pull dengcao/Qwen3-Reranker-0.6B:latest
```

### Подготовка окружения

1. Создайте файл `.env` в корневой директории проекта с токеном Hugging Face:

```env
HUGGINGFACE_HUB_TOKEN=your_huggingface_token_here
```

2. Поместите документы, которые нужно обработать, в папку `documents/`

### Запуск с помощью Docker Compose

Для запуска всех сервисов проекта используйте команду:

```bash
docker-compose up --build
```

### Альтернативный запуск

Для запуска в режиме разработки:

```bash
# Запуск интерактивного сеанса в контейнере
docker run -it --rm --gpus all \
  -v ${PWD}/documents:/app/documents \
  -v ${PWD}/output:/app/output \
  -v ${PWD}/scripts:/app/scripts \
  my-pipeline bash

# Сборка образа
docker build -t bashkir-rag .

# Запуск обработки документов
docker run --gpus all -v ./documents:/app/documents -v ./output:/app/output -v ./.env:/app/.env -e HUGGINGFACE_HUB_TOKEN --network="host" bashkir-rag

# Запуск скрипта в контейнере 
uv run python scripts/ai_chunking.py
```

## Структура проекта

- `scripts/parse_docs_ocr.py`: модуль для конвертации PDF-документов в Markdown с использованием OCR
- `scripts/semantic_chunking.py`: модуль для семантического разбиения документов с помощью HuggingFace эмбеддингов
- `scripts/ai_chunking.py`: модуль для создания векторной базы в Qdrant из семантических чанков
- `scripts/generat_answer.py`: модуль для тестирования подключения к Ollama и генерации ответов
- `pyproject.toml`: файл зависимостей проекта
- `Dockerfile`: определение Docker-образа для контейнеризации приложения
- `docker-compose.yml`: конфигурационный файл для запуска всех сервисов проекта
- `reranker.py`: модуль для переупорядочивания документов по релевантности

## Лицензия

Данный проект распространяется как внутреннее решение для компании Башкирэнерго. За дополнительной информацией обращайтесь к команде разработчиков.