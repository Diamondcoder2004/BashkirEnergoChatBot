from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_ollama import OllamaLLM
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Qdrant
from qdrant_client import QdrantClient
import uvicorn
import logging
from typing import List, Optional
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
COLLECTION_NAME = "bashkir_energo_rubert"  # –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏

# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="RAG API –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ",
    description="API –¥–ª—è –≤–æ–ø—Ä–æ—Å–Ω–æ-–æ—Ç–≤–µ—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ",
    version="1.0.0"
)

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class QuestionRequest(BaseModel):
    question: str
    top_k: Optional[int] = 3

class DocumentResponse(BaseModel):
    content: str
    source: str

class AnswerResponse(BaseModel):
    question: str
    answer: str
    sources: List[DocumentResponse]

class HealthResponse(BaseModel):
    status: str
    service: str
    collection: str

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–µ–π
llm = None
vector_store = None
SERVICE_READY = False


def compress(text: str) -> str:
    """
    Compresses text to 20% of its original volume while preserving key facts.
    
    Args:
        text: Input text to compress
        
    Returns:
        Compressed text
    """
    return llm.invoke(f"–°–æ–∂–º–∏ —Ç–µ–∫—Å—Ç –¥–æ 20% –æ–±—ä—ë–º–∞, —Å–æ—Ö—Ä–∞–Ω–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã:\n\n{text}")

@app.on_event("startup")
async def startup_event():
    global llm, vector_store, SERVICE_READY
    try:
        OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://host.docker.internal:11434")
        QDRANT_HOST = os.getenv("QDRANT_HOST", "qdrant")
        
        logger.info(f"üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ollama: {OLLAMA_HOST}")
        logger.info(f"üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qdrant: {QDRANT_HOST}")
        logger.info(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è: {COLLECTION_NAME}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM
        llm = OllamaLLM(
            model="bambucha/saiga-llama3",
            base_url=OLLAMA_HOST,
            temperature=0.1,
            num_ctx=8192,
            timeout=120
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º HuggingFace
        embeddings = HuggingFaceEmbeddings(
            model_name="MiniLM-L12-v2",  
            encode_kwargs={"normalize_embeddings": True}
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qdrant
        qdrant_client = QdrantClient(host=QDRANT_HOST, port=6333)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        collections = qdrant_client.get_collections()
        collection_names = [col.name for col in collections.collections]
        logger.info(f"üìö –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {collection_names}")
        
        if COLLECTION_NAME not in collection_names:
            logger.warning(f"‚ùå –ö–æ–ª–ª–µ–∫—Ü–∏—è '{COLLECTION_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            SERVICE_READY = False
            return
        
        vector_store = Qdrant(
            client=qdrant_client,
            collection_name=COLLECTION_NAME,
            embeddings=embeddings
        )
        
        # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ Qdrant
        test_results = vector_store.similarity_search("–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–æ", k=1)
        logger.info(f"‚úÖ –¢–µ—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫: –Ω–∞–π–¥–µ–Ω–æ {len(test_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        
        # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ Ollama
        test_response = llm.invoke("–û—Ç–≤–µ—Ç—å 'OK'")
        logger.info(f"‚úÖ –¢–µ—Å—Ç Ollama: {test_response.strip()}")
        
        logger.info("‚úÖ RAG —Å–µ—Ä–≤–∏—Å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        SERVICE_READY = True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG: {e}")
        SERVICE_READY = False

@app.get("/")
async def root():
    return {
        "message": "RAG API –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ", 
        "status": "running",
        "collection": COLLECTION_NAME
    }

@app.get("/health")
async def health():
    return HealthResponse(
        status="ready" if SERVICE_READY else "degraded", 
        service="rag-api",
        collection=COLLECTION_NAME
    )

@app.get("/test")
async def test():
    return {
        "test": "ok", 
        "ready": SERVICE_READY,
        "collection": COLLECTION_NAME
    }

@app.post("/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    if not SERVICE_READY:
        return AnswerResponse(
            question=request.question,
            answer=f"–°–µ—Ä–≤–∏—Å –Ω–µ –≥–æ—Ç–æ–≤. –ö–æ–ª–ª–µ–∫—Ü–∏—è '{COLLECTION_NAME}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.",
            sources=[]
        )
    
    try:
        logger.info(f"üì• –í–æ–ø—Ä–æ—Å: {request.question}")
        logger.info(f"üìÅ –ü–æ–∏—Å–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {COLLECTION_NAME}")
        
        # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        retriever = vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": request.top_k}
        )
        
        docs = retriever.invoke(request.question)
        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)}")
        
        if not docs:
            return AnswerResponse(
                question=request.question,
                answer=f"–í –∫–æ–ª–ª–µ–∫—Ü–∏–∏ '{COLLECTION_NAME}' –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É",
                sources=[]
            )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "\n\n".join([
            f"[–î–æ–∫—É–º–µ–Ω—Ç: {doc.metadata.get('source', 'Unknown')}]\n{doc.page_content}"
            for doc in docs
        ])
        
        logger.info(f"üìÑ –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω ({len(context)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –°–∂–∏–º–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ LLM
        compressed_context = compress(context)
        logger.info(f"üì¶ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–∂–∞—Ç –¥–æ ({len(compressed_context)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è Saiga-llama3
        prompt = f"""–¢—ã - AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–ö–û–ù–¢–ï–ö–°–¢ (–¥–æ–∫—É–º–µ–Ω—Ç—ã –ë–∞—à–∫–∏—Ä—ç–Ω–µ—Ä–≥–æ):
{compressed_context}

–í–û–ü–†–û–°:
{request.question}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –í–ù–ò–ú–ê–¢–ï–õ–¨–ù–û –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–æ–ø—Ä–æ—Å—É
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ï–°–¢–¨ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ - –¥–∞–π —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –¥–µ—Ç–∞–ª—è–º–∏
3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ù–ï–¢ - —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ "–í –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É"
4. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω—ã–º: —É–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã, —Å—Ä–æ–∫–∏, —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —Ç–∞—Ä–∏—Ñ—ã
5. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π
6. –ï—Å–ª–∏ –Ω–∞—Ö–æ–¥–∏—à—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ - –ø–µ—Ä–µ—á–∏—Å–ª–∏ –∏—Ö –≤—Å–µ

–í–ê–ñ–ù–û: –ù–µ –≥–æ–≤–æ—Ä–∏ —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ!

–û–¢–í–ï–¢:"""
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        logger.info("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å Saiga-llama3...")
        answer = llm.invoke(prompt)
        logger.info(f"‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        sources = []
        for doc in docs:
            sources.append(DocumentResponse(
                content=doc.page_content[:500] + "..." if len(doc.page_content) > 500 else doc.page_content,
                source=doc.metadata.get('source', 'Unknown')
            ))
        
        return AnswerResponse(
            question=request.question,
            answer=answer.strip(),
            sources=sources
        )
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–æ–ø—Ä–æ—Å–∞: {e}")
        return AnswerResponse(
            question=request.question,
            answer=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}",
            sources=[]
        )

if __name__ == "__main__":
    uvicorn.run(
        "main:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    )